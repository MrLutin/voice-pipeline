# Voice Pipeline ğŸ¤â†’ğŸ§ â†’ğŸ”Š

Pipeline expÃ©rimental: **Whisper â†’ Claude â†’ XTTS v2**

Transforme de l'audio en rÃ©ponse vocale avec une voix clonÃ©e personnalisÃ©e.

## ğŸ—ï¸ Architecture

```
Audio Input â†’ [Whisper STT] â†’ Texte â†’ [Claude AI] â†’ RÃ©ponse â†’ [XTTS v2 TTS] â†’ Audio Output
                                                                    â†‘
                                                            Voice Sample
```

## ğŸ“‹ PrÃ©requis

- **Python** 3.10+
- **GPU** recommandÃ© (NVIDIA avec CUDA)
- **~6GB VRAM** pour XTTS v2
- **ClÃ© API Anthropic** (`ANTHROPIC_API_KEY`)

## ğŸš€ Installation

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ™ï¸ PrÃ©parer le sample vocal

Place ton sample vocal dans `samples/`:
- Format: **WAV** (16kHz ou 22kHz recommandÃ©)
- DurÃ©e: **6-30 secondes**
- QualitÃ©: Audio propre, sans bruit de fond
- Contenu: Parole naturelle, phrases variÃ©es

## ğŸ“– Utilisation

### Depuis un fichier audio
```bash
python voice_pipeline.py --input question.wav --voice samples/ma_voix.wav
```

### Depuis du texte (skip Whisper)
```bash
python voice_pipeline.py --text "Salut, comment Ã§a va?" --voice samples/ma_voix.wav
```

### Enregistrer depuis le micro
```bash
python voice_pipeline.py --record --voice samples/ma_voix.wav --duration 5
```

### Options
```
--input, -i     Fichier audio d'entrÃ©e
--text, -t      Texte d'entrÃ©e (skip Whisper)
--voice, -v     Sample vocal pour le cloning (requis)
--output, -o    Fichier audio de sortie
--record, -r    Enregistrer depuis le micro
--duration, -d  DurÃ©e d'enregistrement (dÃ©faut: 5s)
--device        Force cuda ou cpu
```

## ğŸ“ Structure

```
voice-pipeline/
â”œâ”€â”€ voice_pipeline.py   # Script principal
â”œâ”€â”€ requirements.txt    # DÃ©pendances
â”œâ”€â”€ samples/            # Samples vocaux pour cloning
â”‚   â””â”€â”€ (ton_sample.wav)
â”œâ”€â”€ output/             # Fichiers gÃ©nÃ©rÃ©s
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

Ã‰dite `voice_pipeline.py` pour ajuster:

```python
WHISPER_MODEL = "base"  # tiny, base, small, medium, large
CLAUDE_MODEL = "claude-haiku-4-5"
LANGUAGE = "fr"
```

## ğŸ› Troubleshooting

### "CUDA out of memory"
- Utilise un modÃ¨le Whisper plus petit (`tiny` ou `base`)
- Ajoute `--device cpu` (plus lent)

### Voix clonÃ©e de mauvaise qualitÃ©
- Utilise un sample plus long (15-30 sec)
- Assure-toi que l'audio est propre
- Ã‰vite la musique/bruit de fond dans le sample

### "No module named 'TTS'"
```bash
pip install coqui-tts
```

## ğŸ“œ License

ExpÃ©rimental â€” Usage personnel uniquement.
XTTS v2 est sous [Coqui Public Model License](https://coqui.ai/cpml).

---

CrÃ©Ã© par **Morwintar** ğŸ–¤
